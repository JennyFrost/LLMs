{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JennyFrost/LLMs/blob/main/LogReg_%26_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txFaJqHyT3e9"
      },
      "source": [
        "def read_infile(infile):\n",
        "    sents, labels = [], []\n",
        "    with open(infile, \"r\", encoding=\"Windows-1251\") as fin:\n",
        "        for line in fin:\n",
        "            line = line.strip()\n",
        "            if line == \"\":\n",
        "                continue\n",
        "            label, sent = line.split()[0], ' '.join(line.split()[1:])\n",
        "            sents.append(sent)\n",
        "            labels.append(label)\n",
        "    return sents, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3se9vKG-T3fD",
        "outputId": "7427947a-66d7-4bc2-f968-d801bbeba1bf"
      },
      "source": [
        "train_data, train_labels = read_infile(\"train.txt\")\n",
        "test_data, test_labels = read_infile(\"test.txt\")\n",
        "print(len(train_labels), len(test_labels))\n",
        "print(set(train_labels))\n",
        "print(train_data[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5452 500\n",
            "{'ENTY:lang', 'ENTY:symbol', 'LOC:state', 'ENTY:body', 'ENTY:cremat', 'ENTY:dismed', 'NUM:money', 'LOC:mount', 'NUM:ord', 'NUM:date', 'LOC:other', 'ENTY:product', 'NUM:weight', 'ABBR:abb', 'LOC:country', 'ENTY:techmeth', 'ENTY:religion', 'ENTY:color', 'ENTY:sport', 'ABBR:exp', 'ENTY:other', 'NUM:count', 'NUM:code', 'ENTY:plant', 'ENTY:veh', 'DESC:manner', 'HUM:desc', 'HUM:ind', 'NUM:period', 'HUM:gr', 'HUM:title', 'LOC:city', 'NUM:perc', 'ENTY:event', 'DESC:def', 'ENTY:animal', 'NUM:speed', 'ENTY:instru', 'DESC:reason', 'ENTY:word', 'NUM:dist', 'ENTY:letter', 'DESC:desc', 'ENTY:substance', 'ENTY:termeq', 'ENTY:currency', 'NUM:temp', 'ENTY:food', 'NUM:volsize', 'NUM:other'}\n",
            "How can I find a list of celebrities ' real names ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3JEt1UpT3fF"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_trf\", disable=[\"parser\", \"ner\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbQTfPS9T3fF"
      },
      "source": [
        "def normalize_sent(data):\n",
        "    if isinstance(data, list):\n",
        "        processed_sents = list(nlp.pipe(data))\n",
        "        return [normalize_sent(sent) for sent in processed_sents]\n",
        "    elif isinstance(data, str):\n",
        "        processed_sent = nlp(data)\n",
        "    else:\n",
        "        processed_sent = data\n",
        "    answer = [token.lemma_ if token.lemma_ != \"-PRON-\" else token.text.lower() for token in processed_sent]\n",
        "\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Hs-zL3T3fG",
        "outputId": "9a0c7d74-693a-4912-d8e5-7123f1895e0c"
      },
      "source": [
        "train_data = normalize_sent(train_data)\n",
        "test_data = normalize_sent(test_data)\n",
        "print(test_data[13])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['who', 'be', 'the', 'first', 'man', 'to', 'fly', 'across', 'the', 'Pacific', 'Ocean', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSkO-UENT3fH"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def remove_punct(sent):\n",
        "    words = [word for word in sent if word not in \",.\\()„\\\"«»;:\\`\"]\n",
        "    words = [word for word in words if word != \"\"]\n",
        "    return words\n",
        "\n",
        "def get_ngrams(sent, ngram_length=3, to_lower=False):\n",
        "    if to_lower:\n",
        "        sent = sent.lower()\n",
        "    sent = remove_punct(sent)\n",
        "    answer = []\n",
        "    for curr_ngram_length in range(1, min(ngram_length, len(sent))+1):\n",
        "        for end in range(curr_ngram_length, len(sent)+1):\n",
        "            start = end-curr_ngram_length\n",
        "            answer.append(' '.join(sent[start:end]))\n",
        "    ngrams = defaultdict(int)\n",
        "    for ngram in answer:\n",
        "        ngrams[ngram] += 1\n",
        "    return ngrams"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jappmcwZT3fI"
      },
      "source": [
        "import tqdm\n",
        "\n",
        "class DataProcessor:\n",
        "\n",
        "    def __init__(self, ngram_length=3, min_count=1):\n",
        "        self.ngram_length = ngram_length\n",
        "        self.min_count = min_count\n",
        "\n",
        "    def fit(self, data):\n",
        "        ngram_counts = defaultdict(int)\n",
        "        for sent in tqdm.notebook.tqdm(data):\n",
        "            sent_ngram_counts = get_ngrams(sent, ngram_length=self.ngram_length)\n",
        "            for ngram in sent_ngram_counts:\n",
        "                ngram_counts[ngram] += 1\n",
        "        self.ngrams = sorted(ngram for ngram, count in ngram_counts.items() if count >= self.min_count)\n",
        "        self.ngram_codes = {ngram: i for i, ngram in enumerate(self.ngrams)}\n",
        "        print(\"{} энграмм в словаре.\".format(len(self.ngrams)))\n",
        "        return self\n",
        "\n",
        "    def transform(self, data):\n",
        "        return [self.transform_sent(sent) for sent in data]\n",
        "\n",
        "    def transform_sent(self, sent):\n",
        "        ngrams = get_ngrams(sent, ngram_length=self.ngram_length)\n",
        "        answer = [0] * len(self.ngrams)\n",
        "        for ngram, count in ngrams.items():\n",
        "            code = self.ngram_codes.get(ngram)\n",
        "            if code is not None:\n",
        "                answer[code] = count\n",
        "        return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYhRmTUZT3fJ"
      },
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class SparseDataProcessor(DataProcessor):\n",
        "\n",
        "    def transform(self, data):\n",
        "        values, rows, columns = [], [], []\n",
        "        for i, sent in enumerate(tqdm.notebook.tqdm(data)):\n",
        "            ngrams = get_ngrams(sent, ngram_length=self.ngram_length)\n",
        "            for ngram, count in ngrams.items():\n",
        "                code = self.ngram_codes.get(ngram)\n",
        "                if code is not None:\n",
        "                    values.append(count)\n",
        "                    rows.append(i)\n",
        "                    columns.append(code)\n",
        "        answer = csr_matrix((values, (rows, columns)), shape=(len(data), len(self.ngram_codes)))\n",
        "        return answer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "02266bcb11d24fcea5b6e2bf4d3baba0",
            "9eeb773db65e421c879b25c4d7f318a5",
            "9049edd1855e4df19588853560c5cc99"
          ]
        },
        "id": "wBHj-XHcT3fJ",
        "outputId": "f85ffcbd-42a3-4258-a36b-a19b859b38e3"
      },
      "source": [
        "data_processor = SparseDataProcessor(min_count=3, ngram_length=3)\n",
        "data_processor.fit(train_data)\n",
        "X_train = data_processor.transform(train_data)\n",
        "X_test = data_processor.transform(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02266bcb11d24fcea5b6e2bf4d3baba0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5452.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "5590 энграмм в словаре.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eeb773db65e421c879b25c4d7f318a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5452.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9049edd1855e4df19588853560c5cc99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svdOJ-JVT3fK"
      },
      "source": [
        "## $Logistic$ $regression$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKds7zmmT3fL",
        "outputId": "4045fd49-30d6-426a-cdfe-7f1fb636436f"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "cls = LogisticRegression(max_iter=500)\n",
        "cls.fit(X_train, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3XpWYdXT3fM",
        "outputId": "a291ccf4-cb61-4d94-8e93-cdbae4ac5962"
      },
      "source": [
        "pred_labels = cls.predict(X_test)\n",
        "print(test_labels[:20])\n",
        "print(pred_labels[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NUM:dist', 'LOC:city', 'HUM:desc', 'DESC:def', 'NUM:date', 'NUM:dist', 'HUM:gr', 'ENTY:plant', 'DESC:reason', 'DESC:def', 'LOC:city', 'HUM:ind', 'NUM:weight', 'HUM:ind', 'NUM:date', 'NUM:other', 'ENTY:substance', 'HUM:ind', 'DESC:def', 'NUM:date']\n",
            "['NUM:dist' 'LOC:other' 'HUM:desc' 'DESC:def' 'NUM:date' 'NUM:dist'\n",
            " 'HUM:gr' 'DESC:def' 'DESC:reason' 'DESC:def' 'LOC:city' 'HUM:ind'\n",
            " 'NUM:weight' 'HUM:ind' 'NUM:date' 'NUM:period' 'ENTY:other' 'HUM:ind'\n",
            " 'DESC:def' 'NUM:date']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0cvq-6pT3fN",
        "outputId": "c3b1807a-2b46-4c15-df6f-ee210b241df3"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "print(\"Корректность: {:.2f}\".format(100 * accuracy))\n",
        "prec, rec, f1, sup = precision_recall_fscore_support(test_labels, pred_labels)\n",
        "print(\"Точность:\")\n",
        "for label, x in zip(cls.classes_, prec):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")\n",
        "print(\"Полнота:\")\n",
        "for label, x in zip(cls.classes_, rec):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")\n",
        "print(\"F1-мера:\")\n",
        "for label, x in zip(cls.classes_, f1):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Корректность: 80.00\n",
            "Точность:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 100.00\n",
            "DESC:def: 77.85\n",
            "DESC:desc: 50.00\n",
            "DESC:manner: 40.00\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 100.00\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 100.00\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 100.00\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 100.00\n",
            "ENTY:letter: 29.41\n",
            "ENTY:other: 100.00\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 71.43\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 53.85\n",
            "ENTY:symbol: 100.00\n",
            "ENTY:techmeth: 75.00\n",
            "ENTY:termeq: 60.00\n",
            "ENTY:veh: 83.08\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 100.00\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 100.00\n",
            "HUM:title: 79.25\n",
            "LOC:city: 71.43\n",
            "LOC:country: 81.82\n",
            "LOC:mount: 100.00\n",
            "LOC:other: 100.00\n",
            "LOC:state: 0.00\n",
            "NUM:code: 100.00\n",
            "NUM:count: 100.00\n",
            "NUM:date: 70.00\n",
            "NUM:dist: 100.00\n",
            "NUM:money: 100.00\n",
            "NUM:ord: 100.00\n",
            "\n",
            "Полнота:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 75.00\n",
            "DESC:def: 100.00\n",
            "DESC:desc: 71.43\n",
            "DESC:manner: 100.00\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 50.00\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 33.33\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 50.00\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 50.00\n",
            "ENTY:letter: 41.67\n",
            "ENTY:other: 20.00\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 33.33\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 100.00\n",
            "ENTY:symbol: 25.00\n",
            "ENTY:techmeth: 100.00\n",
            "ENTY:termeq: 50.00\n",
            "ENTY:veh: 98.18\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 83.33\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 66.67\n",
            "HUM:title: 84.00\n",
            "LOC:city: 71.43\n",
            "LOC:country: 100.00\n",
            "LOC:mount: 95.74\n",
            "LOC:other: 50.00\n",
            "LOC:state: 0.00\n",
            "NUM:code: 41.67\n",
            "NUM:count: 66.67\n",
            "NUM:date: 87.50\n",
            "NUM:dist: 50.00\n",
            "NUM:money: 60.00\n",
            "NUM:ord: 25.00\n",
            "\n",
            "F1-мера:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 85.71\n",
            "DESC:def: 87.54\n",
            "DESC:desc: 58.82\n",
            "DESC:manner: 57.14\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 66.67\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 50.00\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 66.67\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 66.67\n",
            "ENTY:letter: 34.48\n",
            "ENTY:other: 33.33\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 45.45\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 70.00\n",
            "ENTY:symbol: 40.00\n",
            "ENTY:techmeth: 85.71\n",
            "ENTY:termeq: 54.55\n",
            "ENTY:veh: 90.00\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 90.91\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 80.00\n",
            "HUM:title: 81.55\n",
            "LOC:city: 71.43\n",
            "LOC:country: 90.00\n",
            "LOC:mount: 97.83\n",
            "LOC:other: 66.67\n",
            "LOC:state: 0.00\n",
            "NUM:code: 58.82\n",
            "NUM:count: 80.00\n",
            "NUM:date: 77.78\n",
            "NUM:dist: 66.67\n",
            "NUM:money: 75.00\n",
            "NUM:ord: 40.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J4xPflFT3fO"
      },
      "source": [
        "## $Naive$ $Bayes$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EMY6iuoT3fP",
        "outputId": "864287cf-fdfd-4f3c-a203-da446c29b5a0"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "cls_nb = MultinomialNB()\n",
        "cls_nb.fit(X_train, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qTEsRWqT3fQ",
        "outputId": "771ced21-e932-4d52-c370-1b5d4a8dd3a7"
      },
      "source": [
        "pred_labels_nb = cls_nb.predict(X_test)\n",
        "print(test_labels[:20])\n",
        "print(pred_labels_nb[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NUM:dist', 'LOC:city', 'HUM:desc', 'DESC:def', 'NUM:date', 'NUM:dist', 'HUM:gr', 'ENTY:plant', 'DESC:reason', 'DESC:def', 'LOC:city', 'HUM:ind', 'NUM:weight', 'HUM:ind', 'NUM:date', 'NUM:other', 'ENTY:substance', 'HUM:ind', 'DESC:def', 'NUM:date']\n",
            "['NUM:dist' 'LOC:other' 'HUM:ind' 'DESC:def' 'NUM:date' 'NUM:dist'\n",
            " 'HUM:gr' 'DESC:def' 'DESC:reason' 'DESC:def' 'LOC:city' 'HUM:ind'\n",
            " 'DESC:def' 'HUM:ind' 'NUM:date' 'DESC:def' 'LOC:country' 'HUM:ind'\n",
            " 'DESC:def' 'NUM:date']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9kdDtAvT3fQ",
        "outputId": "27334cb2-bfca-4dc9-d574-ec51a212838e"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(test_labels, pred_labels_nb)\n",
        "print(\"Корректность: {:.2f}\".format(100 * accuracy))\n",
        "prec, rec, f1, sup = precision_recall_fscore_support(test_labels, pred_labels)\n",
        "print(\"Точность:\")\n",
        "for label, x in zip(cls_nb.classes_, prec):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")\n",
        "print(\"Полнота:\")\n",
        "for label, x in zip(cls_nb.classes_, rec):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")\n",
        "print(\"F1-мера:\")\n",
        "for label, x in zip(cls_nb.classes_, f1):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\n\")\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Корректность: 67.40\n",
            "Точность:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 100.00\n",
            "DESC:def: 77.85\n",
            "DESC:desc: 50.00\n",
            "DESC:manner: 40.00\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 100.00\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 100.00\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 100.00\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 100.00\n",
            "ENTY:letter: 29.41\n",
            "ENTY:other: 100.00\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 71.43\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 53.85\n",
            "ENTY:symbol: 100.00\n",
            "ENTY:techmeth: 75.00\n",
            "ENTY:termeq: 60.00\n",
            "ENTY:veh: 83.08\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 100.00\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 100.00\n",
            "HUM:title: 79.25\n",
            "LOC:city: 71.43\n",
            "LOC:country: 81.82\n",
            "LOC:mount: 100.00\n",
            "LOC:other: 100.00\n",
            "LOC:state: 0.00\n",
            "NUM:code: 100.00\n",
            "NUM:count: 100.00\n",
            "NUM:date: 70.00\n",
            "NUM:dist: 100.00\n",
            "NUM:money: 100.00\n",
            "NUM:ord: 100.00\n",
            "\n",
            "Полнота:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 75.00\n",
            "DESC:def: 100.00\n",
            "DESC:desc: 71.43\n",
            "DESC:manner: 100.00\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 50.00\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 33.33\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 50.00\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 50.00\n",
            "ENTY:letter: 41.67\n",
            "ENTY:other: 20.00\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 33.33\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 100.00\n",
            "ENTY:symbol: 25.00\n",
            "ENTY:techmeth: 100.00\n",
            "ENTY:termeq: 50.00\n",
            "ENTY:veh: 98.18\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 83.33\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 66.67\n",
            "HUM:title: 84.00\n",
            "LOC:city: 71.43\n",
            "LOC:country: 100.00\n",
            "LOC:mount: 95.74\n",
            "LOC:other: 50.00\n",
            "LOC:state: 0.00\n",
            "NUM:code: 41.67\n",
            "NUM:count: 66.67\n",
            "NUM:date: 87.50\n",
            "NUM:dist: 50.00\n",
            "NUM:money: 60.00\n",
            "NUM:ord: 25.00\n",
            "\n",
            "F1-мера:\n",
            "ABBR:abb: 100.00\n",
            "ABBR:exp: 85.71\n",
            "DESC:def: 87.54\n",
            "DESC:desc: 58.82\n",
            "DESC:manner: 57.14\n",
            "DESC:reason: 100.00\n",
            "ENTY:animal: 66.67\n",
            "ENTY:body: 100.00\n",
            "ENTY:color: 100.00\n",
            "ENTY:cremat: 0.00\n",
            "ENTY:currency: 50.00\n",
            "ENTY:dismed: 0.00\n",
            "ENTY:event: 0.00\n",
            "ENTY:food: 66.67\n",
            "ENTY:instru: 100.00\n",
            "ENTY:lang: 66.67\n",
            "ENTY:letter: 34.48\n",
            "ENTY:other: 33.33\n",
            "ENTY:plant: 0.00\n",
            "ENTY:product: 100.00\n",
            "ENTY:religion: 45.45\n",
            "ENTY:sport: 100.00\n",
            "ENTY:substance: 70.00\n",
            "ENTY:symbol: 40.00\n",
            "ENTY:techmeth: 85.71\n",
            "ENTY:termeq: 54.55\n",
            "ENTY:veh: 90.00\n",
            "ENTY:word: 0.00\n",
            "HUM:desc: 90.91\n",
            "HUM:gr: 100.00\n",
            "HUM:ind: 80.00\n",
            "HUM:title: 81.55\n",
            "LOC:city: 71.43\n",
            "LOC:country: 90.00\n",
            "LOC:mount: 97.83\n",
            "LOC:other: 66.67\n",
            "LOC:state: 0.00\n",
            "NUM:code: 58.82\n",
            "NUM:count: 80.00\n",
            "NUM:date: 77.78\n",
            "NUM:dist: 66.67\n",
            "NUM:money: 75.00\n",
            "NUM:ord: 40.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuBjOwnLUITk"
      },
      "source": [
        "## Определение значимости признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aazbIbQBT3fR",
        "outputId": "0d3f2676-ab2a-49bb-8536-2f5ba36ef421"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.extmath import safe_sparse_dot\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "Y_train = label_binarize(train_labels, cls.classes_, sparse_output=True)\n",
        "feature_counts_by_classes = safe_sparse_dot(Y_train.T, (X_train >= 1), dense_output=True)\n",
        "\n",
        "def get_count_feature_importance(X, Y, classes):\n",
        "    feature_counts_by_classes = safe_sparse_dot(Y.T, (X >= 1), dense_output=True)\n",
        "    log_feature_count = np.log2(1.0 + feature_counts_by_classes.sum(axis=0))\n",
        "    feature_probs_by_classes = feature_counts_by_classes / feature_counts_by_classes.sum(axis=0)\n",
        "    K = Y.shape[1]\n",
        "    feature_weights_by_classes = log_feature_count * (feature_probs_by_classes - 1/K)\n",
        "    answer = defaultdict(dict)\n",
        "    for i, feat_weights in enumerate(feature_weights_by_classes.T):\n",
        "        for label, weight in zip(classes, feat_weights):\n",
        "            if weight > 0:\n",
        "                answer[label][i] = weight\n",
        "    return answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jenya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=['ABBR:abb' 'ABBR:exp' 'DESC:def' 'DESC:desc' 'DESC:manner' 'DESC:reason'\n",
            " 'ENTY:animal' 'ENTY:body' 'ENTY:color' 'ENTY:cremat' 'ENTY:currency'\n",
            " 'ENTY:dismed' 'ENTY:event' 'ENTY:food' 'ENTY:instru' 'ENTY:lang'\n",
            " 'ENTY:letter' 'ENTY:other' 'ENTY:plant' 'ENTY:product' 'ENTY:religion'\n",
            " 'ENTY:sport' 'ENTY:substance' 'ENTY:symbol' 'ENTY:techmeth' 'ENTY:termeq'\n",
            " 'ENTY:veh' 'ENTY:word' 'HUM:desc' 'HUM:gr' 'HUM:ind' 'HUM:title'\n",
            " 'LOC:city' 'LOC:country' 'LOC:mount' 'LOC:other' 'LOC:state' 'NUM:code'\n",
            " 'NUM:count' 'NUM:date' 'NUM:dist' 'NUM:money' 'NUM:ord' 'NUM:other'\n",
            " 'NUM:perc' 'NUM:period' 'NUM:speed' 'NUM:temp' 'NUM:volsize' 'NUM:weight'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "423383wLT3fS"
      },
      "source": [
        "Y_train = label_binarize(train_labels, classes=cls.classes_)\n",
        "\n",
        "importances_by_classes = get_count_feature_importance(X_train, Y_train, classes=cls.classes_)\n",
        "useful_features = set()\n",
        "for label in cls.classes_:\n",
        "    for feat, importance in sorted(importances_by_classes[label].items(), key=lambda x: -x[1])[:400]:\n",
        "        useful_features.add(feat)\n",
        "useful_features = sorted(useful_features)\n",
        "X_train_new = X_train[:,useful_features]\n",
        "X_test_new = X_test[:,useful_features]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkncxXJGT3fT",
        "outputId": "ad22b08a-be02-47d3-fd03-6644c626a473"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "cls_small = LogisticRegression(max_iter=500).fit(X_train_new, train_labels)\n",
        "pred_labels = cls_small.predict(X_test_new)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "print(\"Корректность: {:.2f}\".format(100 * accuracy))\n",
        "f1 = f1_score(test_labels, pred_labels, average=None)\n",
        "for label, x in zip(cls_small.classes_, f1):\n",
        "    print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\t\")\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Корректность: 79.80\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 87.23\tDESC:desc: 58.82\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 66.67\tENTY:body: 100.00\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 29.63\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 45.45\tENTY:sport: 100.00\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 85.71\tENTY:termeq: 54.55\tENTY:veh: 88.52\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 82.35\tLOC:city: 71.43\tLOC:country: 90.00\tLOC:mount: 97.83\tLOC:other: 66.67\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 77.78\tNUM:dist: 66.67\tNUM:money: 75.00\tNUM:ord: 40.00\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0s2JTATT3fU",
        "outputId": "7420216b-669f-42c2-b247-9dd42ab2fd17"
      },
      "source": [
        "importances_by_classes = get_count_feature_importance(X_train, Y_train, classes=cls.classes_)\n",
        "for n_feat_for_class in [100, 200, 400, 1000, 2000]:\n",
        "    useful_features = set()\n",
        "    for label in cls.classes_:\n",
        "        for feat, importance in sorted(importances_by_classes[label].items(), key=lambda x: -x[1])[:n_feat_for_class]:\n",
        "            useful_features.add(feat)\n",
        "    useful_features = sorted(useful_features)\n",
        "    X_train_new = X_train[:,useful_features]\n",
        "    X_test_new = X_test[:,useful_features]\n",
        "    cls_small = LogisticRegression(max_iter=500).fit(X_train_new, train_labels)\n",
        "    pred_labels = cls_small.predict(X_test_new)\n",
        "\n",
        "    accuracy = accuracy_score(test_labels, pred_labels)\n",
        "    print(\"{} признаков, корректность: {:.2f}\".format(len(useful_features), 100 * accuracy))\n",
        "    f1 = f1_score(test_labels, pred_labels, average=None)\n",
        "    for label, x in zip(cls_small.classes_, f1):\n",
        "        print(\"{}: {:.2f}\".format(label, 100*x), end=\"\\t\")\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3473 признаков, корректность: 79.40\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 90.11\tDESC:desc: 45.45\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 64.00\tENTY:body: 100.00\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 26.09\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 57.14\tENTY:sport: 66.67\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 100.00\tENTY:termeq: 54.55\tENTY:veh: 83.33\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 79.21\tLOC:city: 71.43\tLOC:country: 90.00\tLOC:mount: 98.92\tLOC:other: 60.87\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 73.68\tNUM:dist: 66.67\tNUM:money: 57.14\tNUM:ord: 40.00\t\n",
            "4671 признаков, корректность: 79.80\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 87.54\tDESC:desc: 58.82\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 66.67\tENTY:body: 66.67\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 35.71\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 45.45\tENTY:sport: 66.67\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 85.71\tENTY:termeq: 54.55\tENTY:veh: 87.10\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 83.17\tLOC:city: 76.92\tLOC:country: 90.00\tLOC:mount: 97.83\tLOC:other: 66.67\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 73.68\tNUM:dist: 66.67\tNUM:money: 75.00\tNUM:ord: 40.00\t\n",
            "5396 признаков, корректность: 79.80\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 87.23\tDESC:desc: 58.82\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 66.67\tENTY:body: 100.00\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 29.63\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 45.45\tENTY:sport: 100.00\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 85.71\tENTY:termeq: 54.55\tENTY:veh: 88.52\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 82.35\tLOC:city: 71.43\tLOC:country: 90.00\tLOC:mount: 97.83\tLOC:other: 66.67\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 77.78\tNUM:dist: 66.67\tNUM:money: 75.00\tNUM:ord: 40.00\t\n",
            "5590 признаков, корректность: 80.00\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 87.54\tDESC:desc: 58.82\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 66.67\tENTY:body: 100.00\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 34.48\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 45.45\tENTY:sport: 100.00\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 85.71\tENTY:termeq: 54.55\tENTY:veh: 90.00\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 81.55\tLOC:city: 71.43\tLOC:country: 90.00\tLOC:mount: 97.83\tLOC:other: 66.67\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 77.78\tNUM:dist: 66.67\tNUM:money: 75.00\tNUM:ord: 40.00\t\n",
            "5590 признаков, корректность: 80.00\n",
            "ABBR:abb: 100.00\tABBR:exp: 85.71\tDESC:def: 87.54\tDESC:desc: 58.82\tDESC:manner: 57.14\tDESC:reason: 100.00\tENTY:animal: 66.67\tENTY:body: 100.00\tENTY:color: 100.00\tENTY:cremat: 0.00\tENTY:currency: 50.00\tENTY:dismed: 0.00\tENTY:event: 0.00\tENTY:food: 66.67\tENTY:instru: 100.00\tENTY:lang: 66.67\tENTY:letter: 34.48\tENTY:other: 33.33\tENTY:plant: 0.00\tENTY:product: 100.00\tENTY:religion: 45.45\tENTY:sport: 100.00\tENTY:substance: 70.00\tENTY:symbol: 40.00\tENTY:techmeth: 85.71\tENTY:termeq: 54.55\tENTY:veh: 90.00\tENTY:word: 0.00\tHUM:desc: 90.91\tHUM:gr: 100.00\tHUM:ind: 80.00\tHUM:title: 81.55\tLOC:city: 71.43\tLOC:country: 90.00\tLOC:mount: 97.83\tLOC:other: 66.67\tLOC:state: 0.00\tNUM:code: 58.82\tNUM:count: 80.00\tNUM:date: 77.78\tNUM:dist: 66.67\tNUM:money: 75.00\tNUM:ord: 40.00\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVmMdG4NT3fU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}